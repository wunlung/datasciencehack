{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two types of Keras model\n",
    "1. Sequential models: Sequential\n",
    "    - Simply stack layers sequentially\n",
    "2. Non-squential models: Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras layers\n",
    "1. Core abstraction for every model\n",
    "2. In sequential models layers have input, output, input_shape and output_shpae\n",
    "3. Can get weights as list of numpy arrays:\n",
    "    - layer.get_weights()\n",
    "4. Set layer weights with layer.set_weights(weights)\n",
    "5. Each layer has a defining configuration, layer.get_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step to build a sequential model\n",
    "1. Instantiate a Sequential model\n",
    "2. Add layers to it one by one using add\n",
    "3. Compile the model with a loss function, an optimizer and optional evaluation metrics\n",
    "4. Use data to fit the model\n",
    "5. Evaluate model, persist or deploy model, start new experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compiling models 1: loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Option 1: Importing from loss module (preferred)\n",
    "from keras.losses import mean_squared_error\n",
    "model.compile(loss=mean_square, optimizer= # To be filled)\n",
    "\n",
    "# Option 2: Using strings\n",
    "model.compile(loss='mean_square_error', optimizer= # To be filled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compiling models 1: optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Option 1: Load optimizers from module\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "sgd = SGD(lr=0.01,        # learning_rate >= 0\n",
    "          decay=1e-6,     # lr decay after updates\n",
    "          momentum=0.9)   # Momentum parameter use for SGD\n",
    "model.compile(loss=.., optimizer=sgd)\n",
    "\n",
    "# Option 2: pass string(default parameters will be used)\n",
    "model.compile(loss=.., optimizer='sgd')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit evaulate and predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fit a model to train data\n",
    "model.fit(x_train, y_train,\n",
    "         batch_size=32,\n",
    "         epochs=10,\n",
    "         validation_data=(x_val, y_val))\n",
    "# Evaluate on test data\n",
    "evaluate(x_test, y_test, batch_size=32)\n",
    "\n",
    "# Predict labels\n",
    "predict(x_test, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Builidng blocks for MLPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dense layers with activations\n",
    "# Use Drouput for regularization\n",
    "# Build a Sequential model from Dense and Dropout layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dense layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Dense\n",
    "\n",
    "Dense(units,              # Number of output neurons\n",
    "      activation=None,    # Activation function by name\n",
    "      use_bias=True,      # Use bias term or not\n",
    "      kernel_initializer='glorot_uniform',\n",
    "      bias_initializer='zeros')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######  Dropout layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Dropout\n",
    "\n",
    "Dropout(rate,     # Fraction of units to drop\n",
    "       seed=None) # Random seed for reproducibility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Available RNNs in keras\n",
    "1. SimpleRNN - basic RNN\n",
    "2. GRU - Gated Recurisve Unit (2014)\n",
    "3. LSTM - Long short-term memory (1997)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### LSTM layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers.recurrent import LSTM\n",
    "\n",
    "LSTM(units,\n",
    "    activation='tanh',\n",
    "    recurrent_activation='hard_sigmoid',\n",
    "    recurrent_initializer='orthogonal',\n",
    "    recurrent_regularizer=None,\n",
    "    dropout=0.0, recurrent_dropout=0.0,\n",
    "    return_sequence=False) # True if get all intermediate variance | full sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Embedding layers\n",
    "1. Embedding layers for first layer only\n",
    "2. Transform integers into vectors of same length\n",
    "3. Example: [3, 12] embedded as [[0.1, 0.5], [1.3, 4.2]]\n",
    "4. Embed a vocabulary into a vector space, apply to sentences\n",
    "5. 2D input mapped to 3D output, connects to LSTMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers.embeddings import Embedding\n",
    "\n",
    "Embedding(input_dim,          # Vocabulary size\n",
    "         output_dim,          # Output vector length\n",
    "         embeddings_initializer='uniform',\n",
    "         mask_zero=False)     # Mask zero values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models and the functional API\n",
    "1. When you need non-sequential model, use Model\n",
    "2. Once defined, Model can be trained and evaluated exactly like Sequential\n",
    "3. The functional API for Model starts with input(s)\n",
    "4. We then define output(s) by transforming input(s) iteractively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Using the functional API\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "num_classes = 10\n",
    "inputs = Input(shape=(784,))\n",
    "\n",
    "x = Dense(512, activation='relu')(inputs)\n",
    "y = Dense(512, activation='relu')(x)\n",
    "predictions = Dense(num_classes, activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Defining and running a Model\n",
    "model = Model(input=inputs, output=predictions)\n",
    "model.compile(optimizer='sgd',\n",
    "             loss='categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "model.fix(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Serializing Keras model\n",
    "1. Keras model can be saved and loaded\n",
    "2. Full model: architecture, weights and training configuration (HDF5)\n",
    "3. Architecture only(JSON or YAML)\n",
    "4. Weights only (HDF5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Persisting architecture or weights\n",
    "from keras.models import model_from_json\n",
    "\n",
    "# Save model as JSON and weights as HDF5\n",
    "json_string = model.to_json() # model.to_yaml()\n",
    "model.save_weights('weight.h5')\n",
    "\n",
    "# Load from JSON and set weights\n",
    "model = model_from_json(json_string)\n",
    "model.load_weights('weight.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Persisting the full model\n",
    "from keras.models import load_model\n",
    "model.save('full_model.h5')\n",
    "model = load_model('full_model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
