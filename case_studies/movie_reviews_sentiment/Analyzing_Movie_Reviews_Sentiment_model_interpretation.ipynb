{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import necessary dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import text_normalizer as tn\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and normalize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(r'../data/movie_reviews.csv')\n",
    "\n",
    "# take a peek at the data\n",
    "print(dataset.head())\n",
    "reviews = np.array(dataset['review'])\n",
    "sentiments = np.array(dataset['sentiment'])\n",
    "\n",
    "# build train and test datasets\n",
    "train_reviews = reviews[:35000]\n",
    "train_sentiments = sentiments[:35000]\n",
    "test_reviews = reviews[35000:]\n",
    "test_sentiments = sentiments[35000:]\n",
    "\n",
    "# normalize datasets\n",
    "norm_train_reviews = tn.normalize_corpus(train_reviews)\n",
    "norm_test_reviews = tn.normalize_corpus(test_reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use broadcast to increase speed\n",
    "dataset = pd.read_csv(r'../data/movie_reviews.csv')\n",
    "df_train = dataset[:35000]\n",
    "df_test = dataset[35000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tic = time.time()\n",
    "df_train['norm_text'] = df_train.review.apply(lambda x: tn.normalize_doc(x))\n",
    "df_test['norm_text'] = df_test.review.apply(lambda x: tn.normalize_doc(x))\n",
    "toc = time.time()\n",
    "print(\"Time used: {}s\".format(toc-tic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Text Classification Pipeline with The Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# build BOW features on train reviews\n",
    "cv = CountVectorizer(binary=False, min_df=0.0, max_df=1.0, ngram_range=(1,2))\n",
    "cv_train_features = cv.fit_transform(norm_train_reviews)\n",
    "# build Logistic Regression model\n",
    "lr = LogisticRegression()\n",
    "lr.fit(cv_train_features, train_sentiments)\n",
    "\n",
    "# Build Text Classification Pipeline\n",
    "lr_pipeline = make_pipeline(cv, lr)\n",
    "\n",
    "# save the list of prediction classes (positive, negative)\n",
    "classes = list(lr_pipeline.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Analyze Model Prediction Probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr_pipeline.predict(['the lord of the rings is an excellent movie', \n",
    "                     'i hated the recent movie on tv, it was so bad'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(lr_pipeline.predict_proba(['the lord of the rings is an excellent movie', \n",
    "                     'i hated the recent movie on tv, it was so bad']), columns=classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpreting Model Decisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from skater.core.local_interpretation.lime.lime_text import LimeTextExplainer\n",
    "\n",
    "explainer = LimeTextExplainer(class_names=classes)\n",
    "def interpret_classification_model_prediction(doc_index, norm_corpus, corpus, \n",
    "                                              prediction_labels, explainer_obj):\n",
    "    # display model prediction and actual sentiments\n",
    "    print(\"Test document index: {index}\\nActual sentiment: {actual}\\nPredicted sentiment: {predicted}\"\n",
    "      .format(index=doc_index, actual=prediction_labels[doc_index],\n",
    "              predicted=lr_pipeline.predict([norm_corpus[doc_index]])))\n",
    "    # display actual review content\n",
    "    print(\"\\nReview:\", corpus[doc_index])\n",
    "    # display prediction probabilities\n",
    "    print(\"\\nModel Prediction Probabilities:\")\n",
    "    for probs in zip(classes, lr_pipeline.predict_proba([norm_corpus[doc_index]])[0]):\n",
    "        print(probs)\n",
    "    # display model prediction interpretation\n",
    "    exp = explainer.explain_instance(norm_corpus[doc_index], \n",
    "                                     lr_pipeline.predict_proba, num_features=10, \n",
    "                                     labels=[1])\n",
    "    exp.show_in_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doc_index = 100 \n",
    "interpret_classification_model_prediction(doc_index=doc_index, norm_corpus=norm_test_reviews,\n",
    "                                         corpus=test_reviews, prediction_labels=test_sentiments,\n",
    "                                         explainer_obj=explainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doc_index = 2000\n",
    "interpret_classification_model_prediction(doc_index=doc_index, norm_corpus=norm_test_reviews,\n",
    "                                         corpus=test_reviews, prediction_labels=test_sentiments,\n",
    "                                         explainer_obj=explainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doc_index = 347 \n",
    "interpret_classification_model_prediction(doc_index=doc_index, norm_corpus=norm_test_reviews,\n",
    "                                         corpus=test_reviews, prediction_labels=test_sentiments,\n",
    "                                         explainer_obj=explainer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
